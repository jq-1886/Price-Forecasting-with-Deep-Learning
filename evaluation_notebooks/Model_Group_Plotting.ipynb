{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_Group_Plotting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtUUXce4hWUt+pOtWBGXXf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acse-2020/acse2020-acse9-finalreport-acse-jaq15/blob/main/evaluation_notebooks/Model_Group_Plotting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5F7GfFTgUo3"
      },
      "source": [
        "# Imports\n",
        "\n",
        "The cells below handle all the necessary imports to run our models, making use of the public repo feeder_repo, linked <!-- [Text](link) -->\n",
        "[here](https://github.com/acse-jaq15/feeder_repo)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWy9Ay1SGzWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a03248f3-6758-4cc2-c371-361213b69a5e"
      },
      "source": [
        "# clone the feeder repo to get data_reader module and financial time series data\n",
        "!git clone https://github.com/acse-jaq15/feeder_repo.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'feeder_repo'...\n",
            "remote: Enumerating objects: 917, done.\u001b[K\n",
            "remote: Counting objects: 100% (181/181), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 917 (delta 83), reused 179 (delta 81), pack-reused 736\u001b[K\n",
            "Receiving objects: 100% (917/917), 291.80 MiB | 17.09 MiB/s, done.\n",
            "Resolving deltas: 100% (419/419), done.\n",
            "Checking out files: 100% (546/546), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChlUNYaiHGM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364d3d9a-ce04-45d2-c6a0-24bc3c7bf78c"
      },
      "source": [
        "# using '%' to enforce a permanent change of directory\n",
        "%cd feeder_repo/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/feeder_repo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saD-jpvPIfZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e2ccdab-ad0e-4349-c53a-7c10829dbdce"
      },
      "source": [
        "# checking contents listed correctly, should read:\n",
        "# baseline_model.py data data_reader.py model_loader.py saved_models\n",
        "# data LICENSE README.md security_plotter.py\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "base_model.py  data_reader.py  model_loader.py\tsaved_models\n",
            "data\t       LICENSE\t       README.md\tsecurity_plotter.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRqkwo6kZUz_"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_A7eQ_9BNdO"
      },
      "source": [
        "# turning off tensorflow info and warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzVhwND1HAlw"
      },
      "source": [
        "# appending path with 'feeder_repo' string\n",
        "sys.path.append('feeder_repo')\n",
        "\n",
        "# import Data_Reader class from data_reader module\n",
        "from feeder_repo.data_reader import Data_Reader\n",
        "# import Baseline_Model class from base_model module\n",
        "from feeder_repo.base_model import Base_Model\n",
        "# import Security_Plotter class from security_plotter module\n",
        "from feeder_repo.security_plotter import Security_Plotter\n",
        "# import Trained_Model class from model_loader module\n",
        "from feeder_repo.model_loader import Trained_Model\n",
        "# import Untrained_Model class from model_loader module\n",
        "from feeder_repo.model_loader import Untrained_Model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-tNDlXuhiCU",
        "outputId": "7bfac700-f1d4-4ade-c363-3710e46d6550"
      },
      "source": [
        "# checking if the notebook is running on a GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "    print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "    print('and then re-execute this cell.')\n",
        "else:\n",
        "    print(gpu_info)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul 28 11:42:36 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB9wD4Aahs8_"
      },
      "source": [
        "# Generating group plots\n",
        "A loop is used to generate a single plot per security of each model's predictions, along with the actual price and prediction of the dummy model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBlKerL-c4-3"
      },
      "source": [
        "# storing the year of the time series to be used as test data\n",
        "in_yr = 2019\n",
        "# setting our window_length to be 30 days\n",
        "window_len = 30"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkzM7Sx9Qg37"
      },
      "source": [
        "# storing the units of each security in a dictionary, for later plotting\n",
        "unit_dict = {\n",
        "                'Al': 'Price (USD/mt)',\n",
        "                'Cu': 'Price (USD/mt)',\n",
        "                'Corn': 'Price (USd/bushel)',\n",
        "                'EURCHF': 'Spot exchange rate',\n",
        "                'EURUSD': 'Spot exchange rate',\n",
        "                'GBPUSD': 'Spot exchange rate',\n",
        "                'Bund10y': 'Yield (%)',\n",
        "                'Gilt10y': 'Yield (%)',\n",
        "                'Treasury10y': 'Yield (%)',\n",
        "                'Amazon': 'Price (USD)',\n",
        "                'Google': 'Price (USD)',\n",
        "                'Nvidia': 'Price (USD)'\n",
        "            }\n",
        "\n",
        "# storing a list of models\n",
        "model_list = ['CNN', 'CNN_GRU', 'CNN_LSTM',\n",
        "              'GRU', 'GRU_AE', 'GRU_LSTM',\n",
        "              'LSTM', 'LSTM_AE', 'LSTM_GRU',\n",
        "              'MLP', 'MLP_AE']\n",
        "\n",
        "# storing a list of securities\n",
        "security_list = ['Al', 'Cu', 'Corn',\n",
        "                'EURCHF', 'EURUSD', 'GBPUSD',\n",
        "                'Gilt10y', 'Bund10y', 'Treasury10y',\n",
        "                'Amazon', 'Google', 'Nvidia']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGLP1YD83BvM",
        "outputId": "0a0623c2-16e7-436d-e429-40b4f54e6141"
      },
      "source": [
        "# mounting google drive for easy storage of plots and output dataframe\n",
        "from google.colab import drive\n",
        "# mounting the drive\n",
        "drive.mount('/content/gdrive/')\n",
        "# creating a string to save the plots and dataframe respectively\n",
        "plot_path = '/content/gdrive/My Drive/group_plots/'"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X8-QGodgfpm9",
        "outputId": "1184db5d-ab85-4f53-da7f-b4322458b2eb"
      },
      "source": [
        "# looping through each security in security_list\n",
        "for s in security_list:\n",
        "\n",
        "  # creating an instance of Data_Reader class\n",
        "  in_data = Data_Reader(s, in_yr)\n",
        "  # calling class method extract_train_test to generate training and test datasets\n",
        "  in_data.extract_train_test()\n",
        "  # calling class method extract_xy to generate X and y training and test datasets\n",
        "  in_data.extract_xy(window_len)\n",
        "\n",
        "  # assigning X_test and y_test\n",
        "  X_test = in_data.X_test\n",
        "  y_test = in_data.y_test\n",
        "  \n",
        "  # creating a subplot, one per model loop and formatting various parameters\n",
        "  fig, ax = plt.subplots()\n",
        "  plt.xticks(rotation=45)\n",
        "  fig.set_size_inches(12, 6)\n",
        "  fig.suptitle(s+' Actual, Predicted and Dummy Prices', size='xx-large', y=0.92)\n",
        "\n",
        "  # converting to datetime date format and slicing\n",
        "  date_time = in_data.data.date[in_data.train_len + window_len:]\n",
        "  # converting the series to datetime using pandas\n",
        "  series_dates = pd.to_datetime(date_time).dt.date\n",
        "  # resetting index to 0 based\n",
        "  series_dates = series_dates.reset_index(drop=True)\n",
        "  # converting to matplotlib format\n",
        "  series_dates = mdates.date2num(series_dates)\n",
        "\n",
        "  # setting YearLocator\n",
        "  years = mdates.YearLocator()\n",
        "  # setting MonthLocator\n",
        "  months = mdates.MonthLocator()\n",
        "  # setting format to give year and verbose month '2019-Jan'\n",
        "  d_format = mdates.DateFormatter('%Y-%b')\n",
        "\n",
        "  # generating the figure legend\n",
        "  handles, labels = ax.get_legend_handles_labels()\n",
        "  fig.legend(handles, labels, loc='lower center', ncol=3, fontsize='large')\n",
        "\n",
        "  # setting x axis label\n",
        "  ax.set_xlabel('Date')\n",
        "  # getting y axis label from unit_dict\n",
        "  ax.set_ylabel(unit_dict[s])\n",
        "  # informing matplotlib that x axis contains dates\n",
        "  ax.xaxis_date()\n",
        "  ax.set_xticklabels(ax.get_xticks(), rotation=45, ha='right')\n",
        "  # setting minor and major locators and format\n",
        "  ax.xaxis.set_major_locator(months)\n",
        "  ax.xaxis.set_major_formatter(d_format)\n",
        "  ax.xaxis.set_minor_locator(years)\n",
        "\n",
        "  # looping through each model in model_list\n",
        "  for m in model_list:\n",
        "\n",
        "    # conditional logic to set time_distributed bool depending on the model type\n",
        "    # in order to ensure input data is of correct dimensions\n",
        "    if m == 'CNN_GRU' or m == 'CNN_LSTM':\n",
        "      time_distributed = True\n",
        "      # creating another instance of Data_Reader class\n",
        "      in_data_model = Data_Reader(s, in_yr)\n",
        "      # calling class method extract_train_test to generate training and test datasets\n",
        "      in_data_model.extract_train_test()\n",
        "      # calling class method extract_xy to generate X and y training and test datasets\n",
        "      in_data_model.extract_xy(window_len, time_distributed)\n",
        "      # assigning X_test and y_test\n",
        "      X_test_model = in_data_model.X_test\n",
        "    else:\n",
        "      X_test_model = X_test\n",
        "\n",
        "    # clearing the keras session on the back end to ease memory usage\n",
        "    K.clear_session()\n",
        "\n",
        "    # creating an instance of Trained_Model class\n",
        "    trained_model = Trained_Model(m, s)\n",
        "\n",
        "    # creating an instance of Base_Model class using X_test\n",
        "    base_model = Base_Model(X_test, window_len)\n",
        "    # calling predict_y method\n",
        "    base_model.predict_y(in_data.test_len - window_len)\n",
        "\n",
        "    # using the trained model to predict y from X_test\n",
        "    y_pred = trained_model.model.predict(X_test_model)\n",
        "    # assigning y_dummy variable to .y_pred class attribute\n",
        "    y_dummy = base_model.y_pred\n",
        "    \n",
        "    # calling class method extract_real_price to generate unnormalised prices\n",
        "    in_data.extract_real_prices(y_pred, y_dummy)\n",
        "\n",
        "    # assigning actual_price, predicted_price and dummy_price\n",
        "    actual_price = in_data.actual_price\n",
        "    predicted_price = in_data.predicted_price\n",
        "    dummy_price = in_data.dummy_price\n",
        "\n",
        "    # plotting values by accessing each subplot in turn\n",
        "    ax.plot(series_dates, predicted_price, label=m, linewidth=0.9)\n",
        "\n",
        "\n",
        "    # conditional logic to gather dummy model metrics only once\n",
        "    if m == 'MLP_AE':\n",
        "      # assigning y_true variable for metric calculation\n",
        "      y_true = in_data.y_true\n",
        "      \n",
        "      actual_price = in_data.actual_price\n",
        "      dummy_price = in_data.dummy_price\n",
        "      ax.plot(series_dates, actual_price, label='Acutal Price', linewidth=2, linestyle='dotted', color='k')\n",
        "      ax.plot(series_dates, dummy_price, label='Dummy', linewidth=2, linestyle='dotted')\n",
        "\n",
        "    # printing to keep track of progress\n",
        "    print(s+' '+m+' complete')\n",
        "  \n",
        "  ax.legend(bbox_to_anchor=(1.01, 0.5), loc='center left', borderaxespad=0.)\n",
        "\n",
        "  # saving the matplotlib plot after the security loop is complete\n",
        "  plt.savefig(plot_path+s+'_group_plot.png', dpi=600)\n",
        "  # closing the plot to generate a fresh one in the next model loop\n",
        "  plt.clf()\n",
        "  \n",
        "  # print to keep track of progress\n",
        "  print(s+' all completed successfully')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Al CNN complete\n",
            "Al CNN_GRU complete\n",
            "Al CNN_LSTM complete\n",
            "Al GRU complete\n",
            "Al GRU_AE complete\n",
            "Al GRU_LSTM complete\n",
            "Al LSTM complete\n",
            "Al LSTM_AE complete\n",
            "Al LSTM_GRU complete\n",
            "Al MLP complete\n",
            "Al MLP_AE complete\n",
            "Al all completed successfully\n",
            "Cu CNN complete\n",
            "Cu CNN_GRU complete\n",
            "Cu CNN_LSTM complete\n",
            "Cu GRU complete\n",
            "Cu GRU_AE complete\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Cu GRU_LSTM complete\n",
            "Cu LSTM complete\n",
            "Cu LSTM_AE complete\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Cu LSTM_GRU complete\n",
            "Cu MLP complete\n",
            "Cu MLP_AE complete\n",
            "Cu all completed successfully\n",
            "Corn CNN complete\n",
            "Corn CNN_GRU complete\n",
            "Corn CNN_LSTM complete\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Corn GRU complete\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Corn GRU_AE complete\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Corn GRU_LSTM complete\n",
            "Corn LSTM complete\n",
            "Corn LSTM_AE complete\n",
            "Corn LSTM_GRU complete\n",
            "Corn MLP complete\n",
            "Corn MLP_AE complete\n",
            "Corn all completed successfully\n",
            "EURCHF CNN complete\n",
            "EURCHF CNN_GRU complete\n",
            "EURCHF CNN_LSTM complete\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "EURCHF GRU complete\n",
            "EURCHF GRU_AE complete\n",
            "EURCHF GRU_LSTM complete\n",
            "EURCHF LSTM complete\n",
            "EURCHF LSTM_AE complete\n",
            "EURCHF LSTM_GRU complete\n",
            "EURCHF MLP complete\n",
            "EURCHF MLP_AE complete\n",
            "EURCHF all completed successfully\n",
            "EURUSD CNN complete\n",
            "EURUSD CNN_GRU complete\n",
            "EURUSD CNN_LSTM complete\n",
            "EURUSD GRU complete\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "EURUSD GRU_AE complete\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "EURUSD GRU_LSTM complete\n",
            "EURUSD LSTM complete\n",
            "EURUSD LSTM_AE complete\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "EURUSD LSTM_GRU complete\n",
            "EURUSD MLP complete\n",
            "EURUSD MLP_AE complete\n",
            "EURUSD all completed successfully\n",
            "GBPUSD CNN complete\n",
            "GBPUSD CNN_GRU complete\n",
            "GBPUSD CNN_LSTM complete\n",
            "GBPUSD GRU complete\n",
            "GBPUSD GRU_AE complete\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "GBPUSD GRU_LSTM complete\n",
            "GBPUSD LSTM complete\n",
            "GBPUSD LSTM_AE complete\n",
            "GBPUSD LSTM_GRU complete\n",
            "GBPUSD MLP complete\n",
            "GBPUSD MLP_AE complete\n",
            "GBPUSD all completed successfully\n",
            "Gilt10y CNN complete\n",
            "Gilt10y CNN_GRU complete\n",
            "Gilt10y CNN_LSTM complete\n",
            "Gilt10y GRU complete\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Gilt10y GRU_AE complete\n",
            "Gilt10y GRU_LSTM complete\n",
            "Gilt10y LSTM complete\n",
            "Gilt10y LSTM_AE complete\n",
            "Gilt10y LSTM_GRU complete\n",
            "Gilt10y MLP complete\n",
            "Gilt10y MLP_AE complete\n",
            "Gilt10y all completed successfully\n",
            "Bund10y CNN complete\n",
            "Bund10y CNN_GRU complete\n",
            "Bund10y CNN_LSTM complete\n",
            "Bund10y GRU complete\n",
            "Bund10y GRU_AE complete\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Bund10y GRU_LSTM complete\n",
            "Bund10y LSTM complete\n",
            "Bund10y LSTM_AE complete\n",
            "Bund10y LSTM_GRU complete\n",
            "Bund10y MLP complete\n",
            "Bund10y MLP_AE complete\n",
            "Bund10y all completed successfully\n",
            "Treasury10y CNN complete\n",
            "Treasury10y CNN_GRU complete\n",
            "Treasury10y CNN_LSTM complete\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Treasury10y GRU complete\n",
            "Treasury10y GRU_AE complete\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Treasury10y GRU_LSTM complete\n",
            "Treasury10y LSTM complete\n",
            "Treasury10y LSTM_AE complete\n",
            "Treasury10y LSTM_GRU complete\n",
            "Treasury10y MLP complete\n",
            "Treasury10y MLP_AE complete\n",
            "Treasury10y all completed successfully\n",
            "Amazon CNN complete\n",
            "Amazon CNN_GRU complete\n",
            "Amazon CNN_LSTM complete\n",
            "Amazon GRU complete\n",
            "Amazon GRU_AE complete\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Amazon GRU_LSTM complete\n",
            "Amazon LSTM complete\n",
            "Amazon LSTM_AE complete\n",
            "Amazon LSTM_GRU complete\n",
            "Amazon MLP complete\n",
            "Amazon MLP_AE complete\n",
            "Amazon all completed successfully\n",
            "Google CNN complete\n",
            "Google CNN_GRU complete\n",
            "Google CNN_LSTM complete\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Google GRU complete\n",
            "Google GRU_AE complete\n",
            "Google GRU_LSTM complete\n",
            "Google LSTM complete\n",
            "Google LSTM_AE complete\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Google LSTM_GRU complete\n",
            "Google MLP complete\n",
            "Google MLP_AE complete\n",
            "Google all completed successfully\n",
            "Nvidia CNN complete\n",
            "Nvidia CNN_GRU complete\n",
            "Nvidia CNN_LSTM complete\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Nvidia GRU complete\n",
            "Nvidia GRU_AE complete\n",
            "Nvidia GRU_LSTM complete\n",
            "Nvidia LSTM complete\n",
            "Nvidia LSTM_AE complete\n",
            "Nvidia LSTM_GRU complete\n",
            "Nvidia MLP complete\n",
            "Nvidia MLP_AE complete\n",
            "Nvidia all completed successfully\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}